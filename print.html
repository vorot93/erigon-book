<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Erigon Book</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="introduction.html">Introduction</a></li><li class="chapter-item expanded "><a href="mdbx.html"><strong aria-hidden="true">1.</strong> Why MDBX is our storage engine</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="mdbx-freelist.html"><strong aria-hidden="true">1.1.</strong> Freelist</a></li><li class="chapter-item expanded "><a href="mdbx-dupsort.html"><strong aria-hidden="true">1.2.</strong> DupSort feature explanation</a></li></ol></li><li class="chapter-item expanded "><a href="downloader-design.html"><strong aria-hidden="true">2.</strong> Downloader design</a></li><li class="chapter-item expanded "><a href="flat-state-merklization.html"><strong aria-hidden="true">3.</strong> Merklization of flat state</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Erigon Book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p><a href="https://github.com/ledgerwatch/erigon">Erigon</a> is a next-generation Ethereum implementation that introduces several new concepts:</p>
<ul>
<li>A modular client design, enabling parallelized development of the client</li>
<li>New (“flat”) model of storing Ethereum state, allowing a lower disk footprint</li>
<li>Preprocessing of data outside of the storage engine, making database write operations faster by a magnitude</li>
<li>Staged synchronization technique, allowing very fast synchronization</li>
</ul>
<p>This brings the following benefits to the node operators:</p>
<ul>
<li>
<p>Much lower disk footprint</p>
<ul>
<li>1.2TB for archive node, 430GB for pruned node.</li>
</ul>
</li>
<li>
<p>Faster sync speed</p>
<ul>
<li>Over 300 Mgas/s at tip of Ethereum mainnet.</li>
<li>An archive node can be bootstrapped in under 3 days.</li>
<li>Performance improvements allow Erigon to run even on HDD.</li>
</ul>
</li>
<li>
<p>Crash resilience</p>
<ul>
<li>Forceful shutdown or power failure cannot damage Erigon’s database.</li>
</ul>
</li>
<li>
<p>New vision of modularity</p>
<ul>
<li>P2P and web3 RPC services can be run as separate components on a remote machine.</li>
</ul>
</li>
<li>
<p>Full support for OpenEthereum/Parity <code>trace_</code> API, including <code>trace_filter</code></p>
</li>
</ul>
<p>This book documents some of the know-hows that made these achievements possible.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="why-mdbx-is-our-storage-engine"><a class="header" href="#why-mdbx-is-our-storage-engine">Why MDBX is our storage engine</a></h1>
<p>We often get asked why we opted for our current storage engine, <a href="https://github.com/erthink/libmdbx">MDBX</a>.</p>
<h2 id="why-not-leveldb--rocksdb"><a class="header" href="#why-not-leveldb--rocksdb">Why not LevelDB / RocksDB?</a></h2>
<p>Answer is pretty simple: no MVCC.</p>
<p>MVCC allows us to &quot;stitch together&quot; more complex data objects from more normalised form that is stored in the DB, without loss of consistency (if you do it all in a single read-only transaction). This is used quite a lot in the RPC daemon and simplifies the code a lot. You do not need to explicitly link all the data in the application-level code, you just trust that the database will give you consistent snapshot.</p>
<p>Other than that, Level and Rocks are not ACID. This makes them extremely brittle and prone to corruption on application crash or power failure. Given that node sync from genesis is not cheap or instantaneous, this is a non-starter for us.</p>
<h2 id="why-not-badgerdb"><a class="header" href="#why-not-badgerdb">Why not BadgerDB?</a></h2>
<p>BadgerDB, unlike Level or Rocks, does provide transactions. However, there is a next issue we run into: Badger is based on <a href="https://en.wikipedia.org/wiki/Log-structured_merge-tree">Log-structured merge-tree</a>.</p>
<p>Badger (and all LSM-based DBs) has background compaction. It's good for some projects and bad for others.</p>
<p>In Erigon we eliminated most of concurrency (goroutines) for many reasons (too many things happening at the same time). We found that modern SSD (and NVMe) are still pretty bad with concurrent writes - they are way better than HDD, but sequential read is still order of magnitude faster than random reads. Meaning 1 thread touching disk vs 2 threads touching disk - can show 10x degradation.</p>
<p><em>How does this apply to us?</em></p>
<p><strong>We removed parallel writes and moved to control all disk touches</strong>. Now we don't really care about &quot;how much WPS database can handle&quot; because now we can fit all writes into 1 write transaction. Doesn't matter if it happens once per 10 minutes or once per 1 second - as long as it's not thousands of parallel WPS. In LMDB 1 write transaction is equal to 1 fsync syscall - all writes during transaction are happening in RAM.</p>
<p>LSM databases (Badger, LevelDB) are slower on average for random reads, and that read times are more volatile. B+tree is faster and more predictable for random reads.</p>
<h2 id="why-not-boltdb"><a class="header" href="#why-not-boltdb">Why not BoltDB?</a></h2>
<p>Unlike Badger, Bolt is a Go library, providing storage engine based on B+tree. It originally fit well, and we had BoltDB backend available until September 2020.</p>
<p>Bolt lacks certain advanced features that we found useful, like LMDB's sorted duplicates (DupSort). It allows to save space without resorting to compression by storing repetitive keys only once.</p>
<p>Bolt is not actively maintained anymore, <a href="https://github.com/etcd-io/bbolt">although there is an active fork by etcd team</a>. And finally, it is a Go library, precluding usage and binary compatibility with <a href="https://github.com/torquem-ch/silkworm">Silkworm</a> and <a href="https://github.com/rust-ethereum/akula">Akula</a>.</p>
<p>For all these reasons we switched to LMDB.</p>
<h2 id="why-not-lmdb"><a class="header" href="#why-not-lmdb">Why not LMDB?</a></h2>
<p>We used LMDB in the past, but have moved to MDBX which is a fork of LMDB with multiple improvements:</p>
<ul>
<li>Database file growth &quot;geometry&quot; works properly. This is important especially on Windows. In LMDB, one has to specify the memory map size once in advance (currently we use 2Tb by default), and if the database file grows over that limit, one has to restart the process. On Windows, setting memory map size to 2Tb makes database file 2Tb large on the onset, which is not very convenient. With MDBX, memory map size is increased in 2Gb increments. This means occasional remapping, but results in a better user experience.</li>
<li>MDBX has more strict checks on concurrent use of the transaction handles, as well as overlap read and write transaction within the same thread of execution. This allowed us to find some non-obvious bugs and make behaviour more predictable.</li>
<li>Over the period of more than 5 years (since it split from LMDB), MDBX accumulated a lot of safety fixes and heisenbug fixes that are still present in LMDB to the best of our knowledge. Some of them we have discovered during our testing, and MDBX maintainer took them seriously and worked on the fixes promptly.</li>
<li>When it comes to databases that constantly modify data, they generate quite a lot of reclaimable space (also known as &quot;freelist&quot; in LMDB terminology). We had to patch LMDB to fix most serious drawbacks when working with reclaimable space (analysis here: https://github.com/ledgerwatch/erigon/wiki/LMDB-freelist-illustrated-guide). MDBX takes special care of efficient handling of reclaimable space and so far no patches were required.</li>
<li>According to our tests, MDBX performs slightly better on our workloads.</li>
<li>MDBX exposes more internal telemetry - more metrics of what happening inside DB. And we have them in Grafana - to make better decisions on app design. For example, after complete transition to MDBX (removing LMDB support) we will implement &quot;commit half-full transactions&quot; strategy to avoid spill/unspill disk touches. This will simplify our code further without affecting performance.</li>
<li>MDBX has support for &quot;Exclusive open&quot; mode - we using it for DB migrations, to prevent any other reader from accessing the database while DB migration is in progress.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="freelist"><a class="header" href="#freelist">Freelist</a></h1>
<h2 id="how-modifying-the-data-gives-rise-to-freelist"><a class="header" href="#how-modifying-the-data-gives-rise-to-freelist">How modifying the data gives rise to freelist</a></h2>
<p>MDBX supports Multi Version Concurrency Control (MVCC), which is a feature that allows readers of the database &quot;lock in&quot; a view of the database and that that view be &quot;frozen&quot;, undisturbed until the reader disconnects. By reader here we understand any transaction (read-only or writable). There is a limitation on how many readers may simultaneously connect, but once allowed to connect, the reader can view the &quot;frozen&quot; image of the database for as long as required. Maintenance of this property puts constraints on how modification of data can be performed. In particular, all modification of data by writeable transactions need to be done using &quot;copy on write&quot; pattern.
For example, lets imagine this state of the database before modifying an element with value <strong>v5</strong>:
<img src="pics/mdbx-freelist/1.png" alt="" /></p>
<p>To ensure that any reader that is currently looking at the database via the <em>root</em> page pointer, or in fact any reader that may come along during the execution of our modifications, sees undisrupted image of the database, our modification must not change any pages that are reachable from the <em>root</em> pointer. Therefore, we create a <em>new root</em> pointer, and create an alternative B+-tree that will contain previous database image with our modifications applied:
<img src="pics/mdbx-freelist/2.png" alt="" /></p>
<p>As shown on the picture, this modification will require allocation of four pages (either by increasing the file size, or by recycling previously freed space): <code>H</code>, <code>G</code>, <code>I</code>, <code>J</code>, and three pages <code>A</code>, <code>C</code>, <code>F</code> will be marked as potentially recyclable.</p>
<p>The list of these potentially recyclable pages is called freelist. Most of the pages added to the freelist during modifications, cannot be recycled while the writeable transaction is in flight. This is because any readers connecting before the writable transaction commits, will still see the <em>root</em> and all the pages reachable from it. This is similar to the problem garbage collector faces when determining unreachable objects. Starting points of reachability analysis for a garbage collector are global variable and stack of active threads. Similarly, the starting point for the MVCC reachability analysis are the <em>root</em> pointer (only one global variable) and the root pointers grabbed by any active readers:
<img src="pics/mdbx-freelist/3.png" alt="" /></p>
<h2 id="how-deleting-the-data-gives-rise-to-freelist-in-transaction-objects"><a class="header" href="#how-deleting-the-data-gives-rise-to-freelist-in-transaction-objects">How deleting the data gives rise to freelist (in transaction objects)</a></h2>
<p>Deleting is a type of modification and all said before about modifications apply here. With deletions, however, there is one more interesting case - pages that were allocated during the transaction (for modification) but then subsequently freed by deletions. For example, if, after modification shown above, we decided to delete record with values <strong>v9</strong> and <strong>v6</strong>, we would end up with an empty page. But this is the page we have previously allocated, and it is not reachable from the <em>root</em> page pointer, therefore it can be reused straight away. Such pages are called &quot;loose pages&quot;:
<img src="pics/mdbx-freelist/4.png" alt="" /></p>
<p>In the description below, there is a distinction between emptied pages that cannot be recycled yet, and loose pages. There are stored in the different data structures.</p>
<p>In MDBX, data can be deleted in two main ways:</p>
<ol>
<li><strong>deleting keys from a cursor</strong></li>
<li><strong>removing an entire table</strong> (DBI)</li>
</ol>
<p><strong>Deleting keys from a cursor</strong> may cause rebalancing of the B+-tree, because one of the invariants that need to be maintained in a B+-tree says that all pages, except for the root page, must be at least half-full. So, if deleting keys makes a page less than half-full, rebalancing happens - keys and values are moved between pages. Some of these rebalancing cause some pages become empty.</p>
<p><strong>Removing an entire table</strong> (DBI) is a simpler operation than deleting keys from a cursor, because it does not require any rebalancing. Any table always starts with its own root page, and pages are never shared between tables. Therefore, removing an entire table requires finding all the pages that belong to that table.</p>
<p>As we see from above, both ways may produce new empty pages. These empty pages are usually in middle of the database file, and we would like to fill them up (later) with the new data, to prevent the database file from growing too fast.</p>
<p>Since any changes to the database can only occur as a result of a writeable transaction, a transaction object should have some transient data structures to keep the list of pages this transaction emptied. At the time of the transaction commit, these structures are converted into persistent form inside the database.
There are two transient data structures in which a transaction object keeps the IDs of emptied pages:</p>
<ol>
<li><code>MDBX_IDL mt_free_pgs;</code> Type <code>MDBX_IDL</code> stands for &quot;ID list&quot;, and it is a pointer for a list of 8-byte Page IDs, starting with the length of the list at the index 0. Therefore, you can often see <code>txn-&gt;mt_free_pgs[0]</code> as the expression to take the length of the page ID list. This list is pre-allocated to certain size, and therefore, if something needs to be added, such list sometimes needs to be reallocated and moved.</li>
<li><code>MDBX_page *mt_loose_pgs;</code> Type <code>MDBX_page</code> is the structure describing page header. At the beginning of any page, there is a space for either page number of a pointer to another page header. Therefore, <code>mt_loose_pgs</code> is the head of a linked list of page headers, which is convenient for adding and remove pages one by one.</li>
</ol>
<p>Conceptually, these two data structures of a transaction object contain the same kind of information - pages emptied by the transaction, but they are kept and maintained in different forms (slice of IDs and linked list of page headers). The reason for this is as follows. Loose pages from <code>mt_loose_pgs</code> are allowed to be re-used during the same transaction, whereas the pages from <code>mt_free_pgs</code> are not allowed to be re-used. The re-use happens in the function <code>mdbx_page_alloc</code>. This distinction about allowed re-use drives the decisions on when emptied pages are added to one list or another. Pages that have been allocated by this current transaction (either from the expansion of the database or from recycling of the freelist), are known not to be accessed by any other transactions. Such pages end up being marked with <code>P_DIRTY</code> flag. Therefore, having such flag becomes necessary (but not sufficient) criteria for a page to end up in the <code>mt_loose_pgs</code> linked list when emptied.</p>
<ol>
<li>When an entire table is removed, the emptied pages always get added to the <code>mt_free_pgs</code>, ostensibly for efficiency. If there are many page IDs that were emptied, it is very unlikely that many of them have been allocated by the current transaction, so they are all added to the <code>mt_free_pgs</code>, even those some of them might be eligible for <code>mt_loose_pgs</code>. The function where appending to <code>mt_free_pgs</code> is performed is <code>mdbx_drop0</code>.</li>
<li>When rebalancing is performed, if a page has too few entries, and its neighbour page is also just at the threshold or below, the two pages are merged. This merging creates an empty page, and it is added to the <code>mt_loose_pgs</code> if it is marked with <code>P_DIRTY</code> flag and it is not part of the &quot;special&quot; freelist table <code>FREE_DBI</code>. Otherwise, it is added to the <code>mt_free_pgs</code></li>
</ol>
<p>At the transaction commit, both structures <code>mt_free_pgs</code> and <code>mt_loose_pgs</code> are effectively merged together and persisted as a record in the &quot;special&quot; freelist table <code>FREE_DBI</code>. Such record has transaction IDs as a key, and the value is the encoding of the sorted list of page IDs, 8 byte per ID. Transaction IDs increase monotonously throughout the life of the database, so they can be used as &quot;versions&quot; for the purposes of MVCC (Multi Version Concurrency Control). The function that persists these two data structures is <code>mdbx_freelist_save</code>, and it has some nuances that cause performance issues when freelists become large. I will describe the mechanics of this function and the issues later...</p>
<h2 id="old-pages-state-in-the-environment-object"><a class="header" href="#old-pages-state-in-the-environment-object">Old pages state in the environment object</a></h2>
<p>Environment object has a field <code>MDBX_pgstate me_pgstate;</code>, which is a structure consisting on two elements. These two elements are &quot;aliased&quot; (using <code>#define</code> directive) to the name <code>me_pghead</code> and <code>me_pglast</code> accordingly.</p>
<p>The first element, <code>me_pghead</code> is a pointer to the list of page IDs. These are the IDs of pages that can be re-used by the current transaction, if required. Page IDs get into the <code>me_pghead</code> list by being read from the beginning of the freelist table <code>FREE_DBI</code>. You may remember that the keys in the freelist tables are transaction IDs, or in other words, version numbers, indicating &quot;when&quot; certain page IDs became part of the freelist.</p>
<p>The second element, <code>me_pglast</code>, is a number representing the version number (transaction ID), whose freelist entry was read from the <code>FREE_DBI</code> table last, and that entry is now added to the <code>me_pghead</code> list.</p>
<p>Both elements are only modified during the execution of <code>mdbx_page_alloc</code> function. That function tries to search through the old freelists, starting from the oldest one (smallest transaction ID), going to the newer ones, trying to find a run of consecutive pages of desired length. As the search continues, <code>me_pghead</code> gets expanded, and <code>me_pglast</code> increases.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dupsort-feature-explanation"><a class="header" href="#dupsort-feature-explanation">DupSort feature explanation</a></h1>
<p>If KV database has no concept of &quot;Buckets/Tables/Collections&quot; then all keys must have &quot;Prefix&quot;. For example to store
Block bodies and headers need use <code>b</code> and <code>h</code> prefixes:</p>
<pre><code>b1-&gt;encoded_block1
b2-&gt;encoded_block2
b3-&gt;encoded_block3
...
h1-&gt;encoded_header1
h2-&gt;encoded_header2
h3-&gt;encoded_header3
...
</code></pre>
<p>Of course this is 1 byte per key overhead is not very big. But if DB provide concept of named &quot;
Buckets/Tables/Collections&quot; then need create 2 tables <code>b</code> and <code>h</code> and store there key without prefixes. Physically table
names will stored only once (not 1 per key).</p>
<p>But if do 1 step forward - and introduce concept of named &quot;Sub-Buckets/Sub-Tables/Sub-Collections&quot;. Then in will allow
to store physically once longer prefixes.</p>
<p>Let's look at ChangeSets. If block N changed account A from value X to Y:<br />
<code>ChangeSet -&gt; bigEndian(N) -&gt; A -&gt; X</code></p>
<ul>
<li><code>ChangeSet</code> - name of Table</li>
<li><code>bigEndian(N)</code> - name of Sub-Table</li>
<li><code>A</code> - key inside Sub-Table</li>
<li><code>X</code> - value inside Sub-Table</li>
</ul>
<h2 id="mdbx-supports"><a class="header" href="#mdbx-supports">MDBX supports</a></h2>
<p>MDBX supports &quot;tables&quot; (it uses name DBI) and supports &quot;sub-tables&quot; (DupSort DBI).</p>
<pre><code>#MDBX_DUPSORT
    Duplicate keys may be used in the database. (Or, from another perspective,
    keys may have multiple data items, stored in sorted order.) By default
    keys must be unique and may have only a single data item.
</code></pre>
<p>MDBX stores keys in Tree(B+Tree), and keys of sub-tables in sub-Tree (which is linked to Tree of table).</p>
<p>Find value of 1 key, still can be done by single method:</p>
<pre><code>subTableName, keyInSubTable, value := db.Get(tableName, subTableName, keyInSubTable)
</code></pre>
<p>Common pattern to iterate over whole 'normal' table (without sub-table) in a pseudocode:</p>
<pre><code>cursor := transaction.OpenCursor(tableName)
for k, v := cursor.Seek(key); k != nil; k, v = cursor.Next() {
    // logic works with 'k' and 'v' variables
} 
</code></pre>
<p>Iterate over table with sub-table:</p>
<pre><code>cursor := transaction.OpenCursor(tableName)
for k, _ := cursor.SeekDup(subTableName, keyInSubTable); k != nil; k, _ = cursor.Next() {
    // logic works with 'k1', 'k' and 'v' variables
} 
</code></pre>
<p>Enough strait forward. No performance penalty (only profit from smaller database size).</p>
<h2 id="mdbx-in-depth"><a class="header" href="#mdbx-in-depth">MDBX in-depth</a></h2>
<p>Max key size: 2022byte (same for key of sub-Table)
Let's look at ChangeSets. If block N changed account A from value X to Y:<br />
<code>ChangeSet -&gt; bigEndian(N) -&gt; A -&gt; X</code></p>
<ul>
<li><code>ChangeSet</code> - name of Table</li>
<li><code>bigEndian(N)</code> - name of Sub-Table</li>
<li><code>A</code> - key inside Sub-Table</li>
<li><code>X</code> - value inside Sub-Table</li>
</ul>
<pre><code>------------------------------------------------------------------------------------------
    table        | sub-table-name    |      keyAndValueJoinedTogether (no 'value' column)
------------------------------------------------------------------------------------------
  'ChangeSets'   | 
                 | {1}                | {A}+{X}   
                 |                    | {A2}+{X2}
                 | {2}                | {A3}+{X3}   
                 |                    | {A4}+{X4}
                 | ...                | ...               
</code></pre>
<p>It's a bit unexpected, but doesn't change much. All operations are still work:</p>
<pre><code>subTableName, keyAndValueJoinedTogether := cursor.Get(subTableName, keyInSubTable)
{N}, {A}+{X} := cursor.Seek({N}, {A})
</code></pre>
<p>You need manually separate 'A' and 'X'. But, it unleash bunch of new features!
Can iterate in sortet manner all changes in block N. Can read only 1 exact change - even if Block changed many megabytes
of state.</p>
<p>And format of StorageChangeSetBucket:
Loc - location hash (key of storage)</p>
<pre><code>------------------------------------------------------------------------------------------
    table        | sub-table-name    |      keyAndValueJoinedTogether (no 'value' column)
------------------------------------------------------------------------------------------
'StorageChanges' | 
                 | {1}+{A}+{inc1}     | {Loc1}+{X}
                 |                    | {Loc2}+{X2}
                 |                    | {Loc3}+{X3}
                 | {2}+{A}+{inc1}     | {Loc4}+{X4}
                 |                    | {Loc5}+{X5}
                 |                    | {Loc6}+{X6}
                 |                    | ...             
</code></pre>
<p>Because column &quot;keyAndValueJoinedTogether&quot; is stored as key - it has same size limit: 551byte</p>
<h2 id="mdbx-can-you-do-better"><a class="header" href="#mdbx-can-you-do-better">MDBX, can you do better?</a></h2>
<p>By default, for each key MDBX does store small metadata (size of data). Indices by nature - store much-much keys.</p>
<p>If all keys in sub-table (DupSort DBI) have same size - MDBX can store much less metadata.<br />
(Remember! that &quot;keys in sub-table&quot; it's &quot;keyAndValueJoinedTogether&quot; - this thing must have same size). MDBX called this
feature DupFixed (can add this flag to table configuration).</p>
<pre><code>#MDB_DUPFIXED
	 This flag may only be used in combination with #MDB_DUPSORT. This option
	 tells the library that the data items for this database are all the same
	 size, which allows further optimizations in storage and retrieval. When
	 all data items are the same size, the #MDB_GET_MULTIPLE, #MDB_NEXT_MULTIPLE
	 and #MDB_PREV_MULTIPLE cursor operations may be used to retrieve multiple
	 items at once.
</code></pre>
<p>It means in 1 db call you can Get/Put up to 4Kb of sub-table keys.</p>
<h2 id="see-also"><a class="header" href="#see-also">See also</a></h2>
<p><a href="https://github.com/erthink/libmdbx/blob/master/mdbx.h">MDBX docs</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="downloader-design"><a class="header" href="#downloader-design">Downloader design</a></h1>
<p>Infrastructure for downloading headers, block bodies, and receipts that was inherited from go-ethereum does not integrate well with the concept of Staged Sync in Erigon. The code for this infrastructure is mostly contained in <code>eth/downloader</code> package. We would like
to replace it with more minimalistic infrastructure that fits better into &quot;Staged Sync&quot; concept with more judicious use of concurrency and
greater control over database objects, such as transactions.</p>
<h2 id="current-code"><a class="header" href="#current-code">Current code</a></h2>
<p>Code for the new downloader process is split between packages <code>cmd/headers/download</code>, <code>turbo/stages</code>, <code>turbo/stages/headerdownload</code>, <code>/turbo/stages/bodydownload</code>.</p>
<h2 id="high-level-idea-about-header-download"><a class="header" href="#high-level-idea-about-header-download">High-level idea about header download</a></h2>
<p>Header downloader process (represented by the type <code>headerdownload.HeaderDownload</code>) maintains data structure containing the collection of &quot;chain bundles&quot;. Each chain bundle consists of one anchor and some chain links. Each link corresponds to a block header. Links are connected to each other by <code>ParentHash</code> fields. If <code>ParentHash</code> of some links do not point to another link in the same bundle, they all must point to the anchor of this bundle. Here is graphic representation of chain bundle:</p>
<p><img src="pics/chain-bundle-1.png" alt="Chain bundle 1" /></p>
<p>And this is an example of multiple links pointing to the same anchor:</p>
<p><img src="pics/chain-bundle-2.png" alt="Chain bundle 2" /></p>
<p>As Header downloader process generates messages to be sent to other network peers, and as it receives messages from the peers, it
keeps updating its collection of chain bundle. In many cases, new messages from other peers contain more block headers, and
processing of these messages results in extending the existing bundles, merging bundles together, or appearance of new bundles.
All such processing is performed by the member function <code>ProcessSegment</code> declared in the file <code>turbo/stages/headerdownload/headers_algo.go</code>.
As the name of the function suggests, it processes &quot;chain segments&quot; that are received from the peers. What are the chain segments?</p>
<p>Chain segments are simply sequences of headers connected to one another, without any branching. For example, this is a chain segment:</p>
<p><img src="pics/chain-segment.png" alt="Chain segment" /></p>
<p>But this is not:</p>
<p><img src="pics/not-chain-segment.png" alt="Not chain segment" /></p>
<p>All the messages containing groups of headers are first split into segments before they are passed to the <code>ProcessSegment</code> function.
This makes processing algorithms simpler than they would have been if branching bundles needed to be considered.</p>
<p>The goal of adding more segments is to eventually construct a continous chain of headers starting from some pre-determined lowest point.
This chain can be then verified (in the sense of Proof Of Work or Proof of Authority verification), and committed to the database.
Once a chain of headers is committed to the database, the headers it contains may be evicted from memory to make space for more recent headers, and so on. Eventually, the heaviest existing header chain (also known as &quot;canonical chain&quot;) is assembled from segments,
verified, and committed to the database, and turbo-geth can move to the next stage (downloading block bodies).</p>
<h2 id="storing-chain-links-in-memory"><a class="header" href="#storing-chain-links-in-memory">Storing chain links in memory</a></h2>
<p>Every chain link is represented by this structure:</p>
<pre><code>    type Link struct {
    blockHeight uint64
    header      *types.Header
    hash        common.Hash // Hash of the header
    next        []*Link     // Allows iteration over links in ascending block height order
    persisted   bool        // Whether this link comes from the database record
    preverified bool        // Ancestor of pre-verified header
    idx         int         // Index in the heap
}
</code></pre>
<p>Field <code>blockHeight</code> has block height (also known as block number), for faster comparisons when the chain link is used in
data structures like binary heap (extracting block height from the <code>header.Number</code>, which is <code>*big.Int</code> has non-trivial penalty,
apparently).</p>
<p>Field <code>header</code> is simply a pointer to the block header associated with this chain link. Field <code>hash</code> is a shorthand
for <code>header.Hash()</code>, because the latter may also involve some extra work.</p>
<p>Field <code>next</code> is essentially the reverse of the
<code>header.ParentHash</code> links and allows traversing the chain links from parents to children, which is necessary for some algorithms.
Field <code>persisted</code> is a flag that is set when a chain link gets committed into the database (persisted).</p>
<p>Field <code>preverified</code>
(it will probably be replaced by just <code>verified</code> soon) is a flag that is set for set of headers that are known to belong to the
canonical chain (i.e. they have been added to the chain and the probability of them being removed is very close to zero).
The hashes of such pre-verified headers are listed in the file <code>turbo/stages/preverified_hashes_mainnet.go</code> and similar (for other
network). Any header that is a parent of a pre-verified header, is considered to be pre-verified. Theoretically, it would be
enough to only specify one pre-verified header. But in practice, it makes sense to have a lot of them so that verification
does not require loading the entire header chain first.</p>
<p>Field <code>idx</code> has a very specific purpose. When chain link objects are placed into a priority queue (binary heap), it is useful
to remove elements not always from the head of the priority queue (top of the binary heap), but from any location. Implementation
of binary heap in Go allows that using function <code>heap.Remove</code>, which requires integer argument - position of the element in the
heap. Using <code>idx</code> field, the actual position of chain links within binary heap is tracked (it gets updated in the <code>Swap</code> function).</p>
<h2 id="priority-queues-for-persisted-and-non-persisted-chain-links"><a class="header" href="#priority-queues-for-persisted-and-non-persisted-chain-links">Priority queues for persisted and non-persisted chain links</a></h2>
<p>Header download process only allows limited number of chain link in memory (by default 1048576). Currently, half of these &quot;slots&quot; are allocated to the persisted chain links, while another half - to the non-persisted chain links. In order to decide which chain links
to evict when the slots become full, two priority queues are used - one for persisted chain links, another - for non-persisted chain
links. The persisted links priority queue puts the link with the lowest block height on the top, therefore the &quot;oldest&quot; headers are getting
cleaned up from memory first. The non-persisted link priority queue, on the other hand, puts the link with the highest block height on the
top, therefore the &quot;youngest&quot; headers are getting clean up from memory first. The &quot;youngest&quot; headers that got removed, will need to
be re-downloaded again.
The idea about keeping &quot;younger&quot; persisted links and &quot;older&quot; non-persisted links is based on the observation that most processing
is happening on the &quot;boundary&quot; between persisted and non-persisted chains.</p>
<p><img src="pics/chain-links-persistent.png" alt="Chain link persisted" /></p>
<h2 id="how-new-headers-are-queried-from-the-peers"><a class="header" href="#how-new-headers-are-queried-from-the-peers">How new headers are queried from the peers?</a></h2>
<p>In order to keep up the &quot;supply&quot; of new header segments downloaded from the network peers, the header download process regularly issues
two types of queries to the peers:</p>
<ol>
<li>Skeleton query. It is implemented by <code>RequestSkeleton</code> function in the <code>turbo/stages/headerdownload/header_algos.go</code> file. Skeleton
query takes advantage of the <code>Skip</code> attribute of the <code>eth</code> protocol message <code>GetBlockHeaders</code>. If <code>Skip</code> is set to zero, then the
protocol message means querying block headers forming chain segement, i.e., they are following one another. If <code>Skip</code> is not zero
(in the case of <code>RequestSkeleton</code> it is <code>8*192=1536</code>), the protocol message means querying headers separated by 1536 other headers from each other.
For example, message <code>GetBlockHeaders{Number: 1000, Length: 5, Skip: 6}</code>, queries headers with block heights <code>1000</code>, <code>1006</code>, <code>1012</code>,
<code>1018</code>, 1024`. Note that skeleton queries are only generated when current number of non-persisted chain bundles (which is equal to number
of anchors) is below certain threshold (currently 16). This is because processing an answer to a skeleton request would normally create up to 192 new anchors, and then it will take some time for the second type of queries (anchor extension queries) to fill the gaps and so reduce the number of anchors.</li>
<li>Anchor extension query. It is implemented by <code>RequestMoreHeaders</code> function in the <code>turbo/stages/headerdownload/header_algos.go</code> file.
The function uses an auxiliary data structure, <code>anchorQueue</code> to decide which anchors to select for queries first. This structure,
<code>anchorQueue</code> is a priority queue of anchors, priorities by the timestamp of latest anchor extension query issued for an anchor.
Anchors for which the extension queries were not issued for the longest time, come on top. The anchor on top gets repeated query,
but only after certain timeout (currently 5 second) since the last query, and only of the anchor still exists (i.e. it has not been
extended yet). Also, if an anchor gets certain number of extension requests issued (currently 10), but without luck of being extended,
that anchor gets invalidated, and all its descendants get deleted from consideration (<code>invalidateAnchor</code> function). This would happen
if anchor was &quot;fake&quot;, i.e. it corresponds to a header without existing ancestors.</li>
</ol>
<p><img src="pics/header-requests.png" alt="Header requests" /></p>
<p>The picture above illustrates (in a simplified manner) how the two types of queries work together. Time line is from left to right,
block heights increase from bottom to top. We start with some persisted headers (in light blue). Then, a skeleton request is issued
(it always start with <code>highestInDb</code> block height to make sure we make progress even if some data get lost). When response from the
skeleton request is processed, we normally end up with multiple anchors attached to the single-header chain bundles. While there are
many anchors, more skeleton requests are not issued, until the number of anchors goes below certain threshold. At this time, only
anchor extension requests are issued, and the chain segments that arrive in response to those requests, cause the anchors to be
replaced by the segments (extending down), until some chain bundles merge, and, as a result, anchors disappear. If any bundle gets
connected to a persisted chain link (light blue), this allows the header insertions into the database (function <code>InsertHeaders</code> in
<code>turbo/stages/headerdownload/header_algos.go</code> file gets invoked periodically to check there are some non-persisted chain links
are connected to persisted links. After such insertion into the database, the <code>highestInDb</code> marker moves up. This means that the next
skeleton query will target higher block heights. On the far right in the picture, we see the results of the second skeleton query.
Although it does not usually happen, it is shown that the skeleton query returned the header on the same block height which is different
from what we had previously. This is normal occurrence, because we assume that the header chain can fork at any time, therefore
the data structures like chain bundles are used instead of simply chain segments. Eventually, the forked headers will also be persisted
into the database if all their ancestors are also persisted.</p>
<h2 id="how-chain-segments-received-from-the-peers-are-added-to-the-collection-of-chain-bundles"><a class="header" href="#how-chain-segments-received-from-the-peers-are-added-to-the-collection-of-chain-bundles">How chain segments received from the peers are added to the collection of chain bundles.</a></h2>
<p>As mentioned previously, header download process maintains a collection of chain bundles in memory. That collection is &quot;held&quot; by
the fields <code>links</code> and <code>anchors</code> of the type <code>HeaderDownload</code>, declared in the file <code>turbo/stages/headerdownload/header_data_struct.go</code>.
Both of these fields are mappings from <code>common.Hash</code> to a <code>Link</code> pointer or to a <code>Anchor</code> pointer, respectively. As mentioned previously,
there are limits (to prevent memory exhaustion attacks) on the amount of chain links and anchors referenced by these mappings.
In order to enforce these limits, priority queues <code>linkQeue</code>, <code>pesistentLinkQueue</code>, and <code>anchorQueue</code> are used. The mappings themselves
are crucial in the processing of the new header segments received from the peers.
First of all, there is no guarantee that a message received from a peer, contains a chain segment. It may contain a collection of
disparate headers (for example, in a response to the skeleton query), or any branched chain bundle (if a peer decided to send an
unsolicited, but still useful bunch of headers). Therefore, any message received from a peer, needs to be split into chain segments.
This is the job of the <code> SplitIntoSegments</code> function in the <code>turbo/stages/headerdownload/header_algos.go</code> file. It takes a collection
of headers and return a collection of chain segments in a specific order. This order is the ascending order of the lowest block height
in the segment. If we attach segments in such order, we guarantee that we will reconstruct the entire chain bundle, if the message
prior to the splitting was a bundle, as demonstrated on the following illustration.</p>
<p><img src="pics/split-into-segments.png" alt="Split into segments" /></p>
<p>The illustration above also demonstrates that there may be many possible ways to split a chain bundle into segments. The function
<code>SplitIntoSegments</code> implements just one possibility, where the split in done in perhaps more segments that is strictly necessary,
but with the advantage of simpler algorithm.</p>
<p>Once segments are identified and ordered appropriately for the insertion, they are passed into <code>ProcessSegment</code> function, declared
in the <code>turbo/stages/headerdownload/header_algos.go</code> file. This function starts with attempting to find an attachment of the new
segment to an existing link, or an existing anchor, or both. This is the job of functions <code>findLink</code> and <code>findAnchor</code>.
Function <code>findLink</code> is trying, using the <code>links</code> mapping, to find the highest existing link that the new segment can be attached to.</p>
<p><img src="pics/find-link.png" alt="Find link" /></p>
<p>In the illustration above, it is assumed that the chain links marked by the same letters, for example, <code>F</code> and <code>G</code>, are identical,
and they have the same hash, and they can be found using <code>links</code> mapping by that hash. The illustration also demonstrates that it is
possible (and it is quite common) for the header download process to receive the same headers multiple times, like the headers
<code>F</code> and <code>G</code> in the example. This means, in this example, that only chain links <code>A</code> and <code>B</code> will be used to extend the existing
chain bundle, because <code>F</code> and <code>G</code> headers are already present.</p>
<p>Function <code>findAnchor</code> tries to finds (using <code>anchors</code> mapping) the lowest link the in the new segment that can be attached to an
existing anchor.</p>
<p><img src="pics/find-anchor.png" alt="Find anchor" /></p>
<p>While <code>findLink</code> function finds the highest matching links in the existing bundles (via <code>links</code> mapping) and the new segment, the
<code>findAnchor</code> function finds a pair <code>(anchor; link)</code> where anchor's hash is equal to the links's header's hash.</p>
<p>Looking at the <code>ProgressSegment</code> function further, it can be seen that, depending on what <code>findLink</code> and <code>findAnchor</code> functions
return, there can be 6 cases, called <code>connect</code>, <code>extendDown</code> (handles two cases), <code>extendUp</code>, and <code>newAnchor</code> (also handles two cases). These cases are shown schematically on
the following illustration:</p>
<p><img src="pics/process-segment-table.png" alt="Process segment table" /></p>
<p>Note that the illustration assumes that the new chain segment is already &quot;trimmed&quot; correctly (meaning that the headers already
present are detected and removed) before applying one of these 4 functions. Such trimming is performed based on the second
return values from the functions <code>findAnchor</code> (returns <code>start</code> index for trimming) and <code>findLink</code> (returns <code>end</code> index for trimming).</p>
<p>As mentioned above, <code>newAnchor</code> function handles two distinct cases. In the first case, a new anchor is indeed created. In the
second case, the chain segment is attached to the existing anchor. It is distinct from <code>extendUp</code> case, where the new chain
segment is attached to a link, not to an anchor. The same applies to <code>extendDown</code> function. In one case it simply adds
more links to an anchor, effectively making anchor hang lower. In another case, it actually connects two anchors.</p>
<p>It would be more correct to have 6 functions covering 6 cases, but the necessary refactoring has not been performed yet.</p>
<p>Once the new segment is applied to the existing chain bundles, the rest of the <code>ProcessSegment</code> function is dedicated to
removing excessive non-persisted chain links (it makes sense because the beginning of <code>ProcessSegment</code> function is the only
place where the number of chain links stored in memory may grow). Recall that the priority queue used to evict non-persisted
chain links, <code>linkQueue</code>, puts the chain link with the highest block height on the top, to be evicted first. Whenever such
chain links is evicted, not only it is deleted from the <code>links</code> mapping, but also any other pointers to it need to be removed
from other data structures. Namely, the parent of this chain link may keep the pointer in its <code>next</code> field (consequently, the
<code>next</code> field of the parent gets adjusted), and the anchor that may be &quot;hanging&quot; on the link, may keep the pointer in its <code>links</code>
slice (that <code>links</code> slice allows walking from any anchor towards its chain links, for example, for the purpose of anchor invalidation).</p>
<h2 id="how-the-headers-get-verified-according-to-pow-or-poa-rules-before-inserting-into-the-database"><a class="header" href="#how-the-headers-get-verified-according-to-pow-or-poa-rules-before-inserting-into-the-database">How the headers get verified (according to PoW or PoA rules) before inserting into the database?</a></h2>
<p>As mentioned earlier, every chain link has a boolean flag <code>preverified</code>, and this will likely be changed to simply <code>verified</code> soon.
Why? There are three ways in which a header can be verified:</p>
<ol>
<li>Pre-verification by hash. For headers that are ancestors (parent, parent of parent, etc.) of some headers that are known to be
contained in the canonical chain and will never be reorganised, no verification needs to be performed. For some public chains,
like main net, and some test nets, the list of such preverified headers is included into the source code of turbo-geth (it gets
updated before each release, this will be included in the <code>RELEASE_INSTRUCTIONS.md</code> in the future).</li>
<li>Pre-verification by preverified descendant. Once a new preveried header gets discovered (either by hash or by descendant), its
parent header also gets marked as preverified, and so on, until either the chain of links stops, or the marking encounters already
preverified header. This is implemented in the function <code>markPreverified</code> in the <code>turbo/stages/headerdownload/header_algos.go</code> file.
This function is called from all 4 functions that apply new chain segment to the chain bundles (<code>connect</code>, <code>extendDown</code>, <code>extendUp</code>,
<code>newAnchor</code>). That way, marking of the preverified headers does not require dedicated processing step.</li>
<li>Verification of headers beyond previously known canonical chain. Together with the &quot;preverified hashes&quot;, source code is shipped
with a number, which is the block height of the last preverified header. Consequently, if a downloaded header has a higher block height,
it needs to be verified by the rules of PoW and PoA. Currently this happens as a part of insertion of the headers into the database.
However, soon this will change, and such verification will be applied as a separate processing step, setting up the <code>verified</code> flags
on the chain link objects. The reason why it needs to be performed as a separate processing step is that Consensus Engine separation
project goes into the direction of asynchronous interaction between &quot;Core&quot; and &quot;Consensus Engine&quot;. That means that requests for verification
will be issued to the Consensus Engine, but they will be responded to asynchronously, and other things (like downloading more headers
or inserting preceding headers into the database) should be allowed to happen in the meantime. This is why <code>preverified</code> flag is likely
to be generalised into <code>verified</code> flag, when it happens.</li>
</ol>
<h2 id="how-the-headers-get-inserted-into-the-database"><a class="header" href="#how-the-headers-get-inserted-into-the-database">How the headers get inserted into the database?</a></h2>
<p>As mentioned earlier, chain links that have been inserted into the database (persisted) do not get immediately removed from memory,
but some number of them stays until evicted. One reason to keep some of them around is to make sure that any branching occurring from
the persisted links will be detected and processed correctly. Another reason to keep some of them around is that the persisted link
with the highest block height serve as initiators for further insertions. Since persisted chain links have their <code>persisted</code> flag on,
and non-persisted ones have their <code>persisted</code> flag off, the boundary between the values of this flag is used to determine when more
insertion into the database should occur.</p>
<p><img src="pics/insert-list.png" alt="Insert list" /></p>
<p>As shown in the illustration above, the chain links &quot;eligible&quot; for insertion are detected and added to the <code>insertList</code>, which is
a member field of the header download process object. How does this detection happen? One way would be to somehow keep the record
of the persisted chain links with the highest block height, and then periodically check if they become connected to some
non-persisted chain links. However, this would be inefficient. Instead, if we look at the table of 4 operations performed in
the <code>ProcessSegment</code> function, we can notice that only <code>extendUp</code> and <code>connect</code> operations can create a situation where
persisted link is connected to a non-persisted link. And this is where (in the functions <code>extendUp</code> and <code>connect</code>) the <code>insertList</code> gets modified.
What happens periodically is the call to the function <code>InsertHeaders</code> declared in the <code>turbo/stages/headerdownload/header_algos.go</code> file.
This function attempts the iteration over <code>insertList</code>. It only considers the chain links that have been pre-verified (if the are
below the <code>preverifiedHeight</code>) or otherwise it verifies them just before insertion. As mentioned earlier, this mechanism will change.
Very likely, there will be another function, let's say <code>VerifyHeaders</code> that will iterate over <code>insertList</code> and issue asynchronous
verification requests to the &quot;Consensus Engine&quot; for those headers that are not marked as <code>verified</code>. It is likely that chain links
will need an extra field, let's say <code>verifyDeadline</code> that would contain the time when the previously issued verification request
expires and a new one needs to be issued (to deal with potentially unreliable Consensus Engine). After such modification, the
<code>InsertHeaders</code> function will not perform the header verification itself, but instead will simply expect the <code>verified</code> flag to be
set for any header before it can get inserted into the database.
If the header is selected for insertion, it gets removed from the <code>insertList</code>, and it also needs to be moved from non-persisted
priority queue to persisted priority queue. This is where the <code>idx</code> member field is useful, because it allows invoking <code>heap.Remove(hd.linkQueue, link.idx)</code> to remove the chain link from the non-persisted priority queue regardless whether it is on the top or
not. Note that if there is an error with insertion, the chain link gets removed from the non-persisted priority queue, but does not
get added to the persisted priority queue. Perhaps it is a bug that it does not get removed from all data structures altogether.</p>
<p>The actual insertion of the headers into the database is delegated to the function <code>hf</code> that is passed into <code>InsertHeaders</code> as an argument.
This indirection exists for two reasons: to make <code>InsertHeaders</code> function smaller in size, and also to assist writing unit tests
that do not necessarily need to insert anything into the database, but can keep headers ephemerally or simply do nothing.</p>
<p>Since the <code>InsertHeaders</code> function is one of the two places where the number of persisted chain links can increase (another place is
<code>RecordFromDb</code> function that is called once in the very beginning of the whole downloading process to read the initial set of
persisted chan links from the database), at the end of this function there is code that enforces the limit on the persisted chain links
in memory. Because there are no anchors below the &quot;persisted links&quot; line, and also the persisted link priority queue evicts the oldest
links first, there is no need to adjust <code>next</code> fields on the parent links (parent links would have been evicted before children) or
<code>links</code> field of the anchors (there are no anchors there), as it was done when limiting non-persisted chain links.</p>
<p>In the non-testing settings, the role of <code>hf</code> function passed to <code>InsertHeaders</code> for the actual insertion into the database, is played
by the <code>FeedHeader</code> function of the <code>HeaderInserter</code> type (note it is different from <code>HeaderDownload</code> type that is used as a &quot;receiver&quot;
for most other functions described earlier). The job of this function is to insert one header at a time. An object of type
<code>HeaderInserter</code> has all the necessary context to perform this job. For example, its member field <code>batch</code> is effectively a database handle
with some buffering attached to it (also called &quot;mutation&quot; sometimes). First of all, function <code>FeedHeader</code> tries to establish
whether the newly presented header will affect what will be considered the &quot;best header&quot; (or in other words, &quot;tip of the canonical chain&quot;).
This could happen either due to adding a child header to the parent which was the &quot;best header&quot; (most common occurrence), or due to
so-called reorg, where an alternative branch becomes the place of the &quot;best header&quot;. Currently, this check for whether the new header will
be the best header, is done by comparing &quot;total difficulties&quot;, which is the concept taken from EtHash consensus, and &quot;shoehorned&quot; into
Clique consensus (by declaring that &quot;out-of-order&quot; signed headers have difficulty 1, and &quot;in-order&quot; signed headers have difficulty 2).
With the separation of Consensus Engine, this will need to change. Instead of relying on the notion of total difficulty, the insertion
process will need to (asynchronously) ask the Consensus Engine to compare the existing &quot;best header&quot; with the new header to see if the new
one is better than the &quot;best&quot;. Most likely it will lead to further decomposition of the <code>FeedHeader</code> function.</p>
<p><img src="pics/best-header.png" alt="Best header" /></p>
<p>In the case if the new header is to become the best header, and important thing to calculate is so-called <code>forkingPoint</code>. On the illustration
above, two cases of replacing of the best header are shown. The first is a trivial one, when the chain simply grows, and in this case
the previous best header (parent of the new header) is the <code>forkingPoint</code> (although, technically, there is no forking). In the second case,
there is actual forking, and the <code>forkingPoint</code> is found by traversing the headers from the new header via <code>ParentHash</code> &quot;pointers&quot;, until
a header currently belonging to the &quot;best chain&quot; (or in other words, &quot;canonical chain&quot;) is found. The processing of this second case
can be seen in the code of the <code>FeedHeader</code> function as the loop over <code>ancestor</code>, <code>ancestorHeight</code> and <code>ancestorHash</code>. As expected, the
loop terminates upon the equality of the canonical hash of given height (<code>ch</code>) and the <code>ancestorHash</code>.</p>
<p>If the best header is getting replaced, a couple of special records in the database get updated: <code>HeadHeaderHash</code> (hash of the &quot;best header&quot;),
<code>StageProcess(stages.Headers)</code> - block number indicating how far the &quot;Headers&quot; stage has advanced. Also, <code>unwindPoint</code> member field of
the <code>HeaderInserter</code> is being updated, so that at the end of the inserting a group of block, the &quot;deepest&quot; forking point is known, and
this is where the unwinding of all stages will need to be performed.</p>
<p>Regardless of whether the best header is replaced or not, two other database records are updated - total difficulty of the new header
(this is likely to be moved to the Consensus Engine in the future), and the mapping of hash of the new header to its RLP encoding.</p>
<h2 id="construction-of-the-headers-sync-stage"><a class="header" href="#construction-of-the-headers-sync-stage">Construction of the Headers Sync stage</a></h2>
<p>Now most of the parts necessary for the construction of the Headers Sync stage have been described. The code of the Headers Sync stage
(not yet integrated into the default Staged Sync of turbo-geth, TODO will be posted further down) is in <code>eth/stagedsync/stage_headers_new.go</code>.
As usual, a definition of a sync stage consists of two functions. The first function is invoked when the sync is moving in forward direction,
i.e. when the block numbers are increasing. The second function is invoked only when there is unwinding (this is triggered when &quot;best header&quot;
is replaced by a new header, which is not the direct descendant of the &quot;best header&quot;, as illustrated earlier). For the Headers Sync stage,
these two functions are <code>HeadersForward</code> and <code>HeadersUnwind</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="merklization-of-flat-state"><a class="header" href="#merklization-of-flat-state">Merklization of flat state</a></h1>
<p>Ethereum network produces checkpoints of the Ethereum State after every block. These checkpoints come in a form of
32-byte binary string, which is the root hash of the Merkle tree constructed out of the accounts in the state. This root
hash is often referred to as &quot;State root&quot;. It is part of block header, and is contained in the field <code>Root</code> of the type
<code>Header</code> <a href="../../core/types/block.go">core/types/block.go</a></p>
<p>Prior to Byzantium release, the state root was also part of every transaction receipt, and was contained in the
field <code>PostState</code>
of the type <code>Receipt</code> <a href="../../core/types/receipt.go">core/types/receipt.go</a>.</p>
<p>To keep the Merkle Patricia trie of Ethereum state balanced, all the keys (either addresses of Ethereum accounts and
contracts, or storage positions within contract storage) are converted into their respective hashes using <code>Keccak256</code>
hash function.
<code>PlainStateBucket</code> stores state with keys before hashing, <code>CurrentStateBucket</code> store same data but keys are hashed.</p>
<h2 id="hexary-radix-patricia-tree"><a class="header" href="#hexary-radix-patricia-tree">Hexary radix &quot;Patricia&quot; tree</a></h2>
<p>Ethereum uses hexary (radix == 16) radix tree to guide the algorithm of computing the state root. For the purposes of
illustrations, we will use trees with radix 4 (because radix 16 requires many more items for &quot;interesting&quot; features to
appear). We start from a set of randomly looking keys, 2 bytes (or 8 quaternary digits) each.</p>
<p><img src="pics/prefix_groups_1.png" alt="prefix_groups_1" /></p>
<p>Next, we sort them in lexicographic order.</p>
<p><img src="pics/prefix_groups_2.png" alt="prefix_groups_2" /></p>
<p>Next, we introduce the notion of a prefix group. Collection of adjacent keys form a prefix group if these keys share the
same prefix, and no other keys share this prefix. Here are the prefix groups for our example:</p>
<p><img src="pics/prefix_groups_3.png" alt="prefix_groups_3" /></p>
<p>The entire collection of keys form one implicit prefix group, with the empty prefix.</p>
<p>Merkle Patricia tree hashing rules first remove redundant parts of each key within groups, making key-value pairs
so-called &quot;leaf nodes&quot;. To produce the hash of a leaf node, one applies the hash function to the two-piece RLP (
Recursive Length Prefix). The first piece is the representation of the non-redundant part of the key. And the second
piece is the representation of the leaf value corresponding to the key, as shown in the member function <code>hashChildren</code>
of the type <code>hasher</code> <a href="../../turbo/trie/hasher.go">turbo/trie/hasher.go</a>, under the <code>*shortNode</code> case.</p>
<p>Hashes of the elements within a prefix group are combined into so-called &quot;branch nodes&quot;. They correspond to the
types <code>duoNode</code> (for prefix groups with exactly two elements) and <code>fullNode</code> in the
file <a href="../../turbo/trie/node.go">turbo/trie/node.go</a>. To produce the hash of a branch node, one represents it as an array
of 17 elements (17-th element is for the attached leaf, if exists). The positions in the array that do not have
corresponding elements in the prefix group are filled with empty strings. This is shown in the member
function <code>hashChildren</code> of the type <code>hasher</code> <a href="../../turbo/trie/hasher.go">turbo/trie/hasher.go</a>, under the <code>*duoNode</code>
and
<code>*fullNode</code> cases.</p>
<p>Sometimes, nested prefix groups have longer prefixes than 1-digit extension of their encompassing prefix group, as it is
the case in the group of items <code>12, 13</code> or in the group of items <code>29, 30, 31</code>. Such cases give rise to so-called &quot;
extension nodes&quot;. However, the value in an extension node is always the representation of a prefix group, rather than a
leaf. To produce the hash of an extension node, one applies the hash function to the two-piece RLP. The first piece is
the representation of the non-redundant part of the key. The second part is the hash of the branch node representing the
prefix group. This shown in the member function <code>hashChildren</code> of the
type <code>hasher</code> <a href="../../turbo/trie/hasher.go">turbo/trie/hasher.go</a>, under the <code>*shortNode</code> case.</p>
<p>This is the illustration of resulting leaf nodes, branch nodes, and extension nodes for our example:</p>
<p><img src="pics/prefix_groups_4.png" alt="prefix_groups_4" /></p>
<h2 id="separation-of-keys-and-the-structure"><a class="header" href="#separation-of-keys-and-the-structure">Separation of keys and the structure</a></h2>
<p>Our goal here will be to construct an algorithm that can produce the hash of the Merkle Patricia Tree of a sorted
sequence of key-value pair, in one simple pass (i.e. without look-aheads and buffering, but with a stack). Another
goal (perhaps more important)
is to be able to split the sequence of key-value pairs into arbitrary chunks of consecutive keys, and reconstruct the
root hash from hashes of the individual chunks (note that a chunk might need to have more than one hash).</p>
<p>Let's say that we would like to split the ordered sequence of 32 key-value pairs into 4 chunks, 8 pairs in each. We
would then like to compute the hashes (there might be more than one hash per chunk) of each chunk separately. After
that, we would like to combine the hashes of the chunks into the root hash.</p>
<p>Our approach would be to generate some additional information, which we will call &quot;structural information&quot;, for each
chunk, as well as for the composition of chunks. This structural information can be a sequence of these &quot;opcodes&quot;:</p>
<ol>
<li><code>LEAF length-of-key</code></li>
<li><code>LEAFHASH length-of-key</code></li>
<li><code>EXTENSION key</code></li>
<li><code>EXTENSIONHASH key</code></li>
<li><code>BRANCH set-of-digits</code></li>
<li><code>BRANCHHASH set-of-digits</code></li>
<li><code>HASH number-of-hashes</code></li>
</ol>
<p>The description of semantics will require the introduction of two stacks, which always have the same length. One of the
stacks (we call it &quot;hash stack&quot;) contains hashes produced by opcodes. Another stack (we call it &quot;node stack&quot;)
contains leaf nodes, branch nodes, or extension nodes of the trie being built. In some cases, where the presence of a
node is not required, the corresponding entry in the node stack is empty, or <code>nil</code>. As well as the stack, the
description requires the introduction of two input sequences (or &quot;tapes&quot;). The first tape contains key-value pairs, each
pair can be viewed as two opaque binary strings of arbitrary length, usually with the requirement that the whole
sequence is sorted by the lexicographic order of the keys, and all the keys are distinct. The second tape contains
hashes, each 32 bytes long.</p>
<p>N.B. Though there two stacks, we can sometimes just say &quot;the stack&quot;, since they are always of the same size and are
operated upon in unison. For example, when we say that XXX pops something from the stack, we mean that XXX pops 1 item
from the hash stack and 1 item from the node stack, but then only one of those two items may be used later and the other
may be discarded by XXX.</p>
<p><code>LEAF</code> opcode consumes the next key-value pair from the first tape, creates a new leaf node and pushes it onto the node
stack. It also pushes the hash of that node onto the hash stack. The operand
<code>length-of-key</code> specifies how many digits of the key become part of the leaf node. For example, for the leaf <code>11</code>
in our example, it will be 6 digits, and for the leaf <code>12</code>, it will be 4 digits. Special case of <code>length-of-key</code>
being zero, pushes the value onto the stack and discards the key.</p>
<p><code>LEAFHASH</code> has almost the same semantics as <code>LEAF</code>, with the difference that it does not need to produce the leaf node,
but only its hash (which can be more efficient in terms of allocations). It places <code>nil</code> onto the node stack.</p>
<p><code>EXTENSION</code> opcode has a key as its operand. This key is a sequence of digits, which, in our example, can only be of
length 1, but generally, it can be longer. The action of this opcode is to pop one item from the stack, create an
extension node with the key provided in the operand, and the value being the item popped from the stack, and push this
extension node onto the node stack (and push its hash onto the hash stack).</p>
<p><code>EXTENSIONHASH</code> has almost the same semantics as <code>EXTENSION</code>, with the difference that it does not need to produce the
extension node, but only its hash (which can be more efficient in terms of allocations). It places <code>nil</code> onto the node
stack.</p>
<p><code>BRANCH</code> opcode has a set of hex digits as its operand. This set can be encoded as a bitset, for example. The action of
this opcode is to pop the same number of items from the stack as the number of digits in the operand's set, create a
branch node, and push it onto the node stack (and push its hash onto the hash stack). Sets of digits can be seen as the
horizontal rectangles on the picture <code>prefix_groups_4</code>. The correspondence between digits in the operand's set and the
items popped from the stack is as follows. The top of the stack (the item being popped off first)
corresponds to the highest digit, and the item being popped off last corresponds to the lowest digit in the set.</p>
<p><code>BRANCHHASH</code> opcode is similar to the <code>BRANCH</code> with the difference is that instead of constructing the branch node, it
only creates its 32-byte hash. It places hash of the node onto the hash stack, and <code>nil</code> onto the node stack.</p>
<p><code>HASH</code> opcode takes specified number of hashes from the input sequence (tape) of hashes, and places them on the hash
stack. It also places the same number of <code>nil</code> entries onto the node stack. The first item consumed ends up the deepest
on the stack, the last item consumed ends up on the top of the stack.</p>
<p>This is the structural information for the chunk containing leaves from <code>0</code> to <code>7</code> (inclusive):</p>
<pre><code>LEAF 5
LEAF 5
BRANCH 12
LEAF 5
LEAF 5
LEAF 5
BRANCH 023
LEAF 6
LEAF 6
BRANCH 0123
LEAF 5
</code></pre>
<p>After executing these opcodes against the chunk, we will have 2 items on the stack, first representing the branch node (
or its hash) for the prefix group of leaves <code>0</code> to <code>6</code>, and the second representing one leaf node for the leaf
<code>7</code>. It can be observed that if we did not see what the next key after the leaf <code>7</code> is, we would not know the operand
for the last <code>LEAF</code> opcode. If the next key started with the prefix <code>101</code> instead of <code>103</code>, the last opcode could have
been <code>LEAF 4</code> (because leaves <code>7</code> and <code>8</code> would have formed a prefix group).</p>
<p>After hashing the first chunk, the tree would look as follows.
<img src="pics/prefix_groups_5.png" alt="prefix_groups_5" /></p>
<p>If we apply the same to produce the next chunk of 8 leaves, we will get to the following picture.
<img src="pics/prefix_groups_6.png" alt="prefix_groups_6" /></p>
<p>And, after hashing the two remaining chunks.
<img src="pics/prefix_groups_7.png" alt="prefix_groups_7" /></p>
<p>Now, if we were given the sequence of these hashes, we need to combine them to produce the root hash.</p>
<pre><code>HASH 3
BRANCH 13
HASH 5
BRANCH 12
HASH 1
BRANCH 01
BRANCH 03
BRANCH 0123
HASH 5
BRANCH 012
BRANCH 013
HASH 1
BRANCH 0123
</code></pre>
<p>These opcodes are implemented by the type <code>HashBuilder</code> (implements the interface <code>structInfoReceiver</code>)
in <a href="../../turbo/trie/hashbuilder.go">turbo/trie/hashbuilder.go</a></p>
<h2 id="multiproofs"><a class="header" href="#multiproofs">Multiproofs</a></h2>
<p>Encoding structural information separately from the sequences of key-value pairs and hashes allows describing
so-called &quot;multiproofs&quot;. Suppose that we know the root hash of the sequence of key-value pairs for our example, but we
do not know any of the pairs themselves. And we ask someone to reveal keys and value for the leaves <code>3</code>, <code>8</code>, <code>22</code>
and <code>23</code>, and enough information to prove to us that the revealed keys and values indeed belong to the sequence. Here is
the picture that gives the idea of which hashes need to be provided together with the selected key-value pairs.
<img src="pics/prefix_groups_8.png" alt="prefix_groups_8" /></p>
<p>And here is the corresponding structural information:</p>
<pre><code>HASH 2
LEAF 5
HASH 1
BRANCH 023
HASH 2
BRANCH 0123
HASH 1
LEAF 4
HASH 2
BRANCH 023
HASH 3
BRANCH 0123
HASH 2
LEAF 5
LEAF 5
BRANCH 012
BRANCH 013
BRANCH 0123
</code></pre>
<p>We can think of a multiproof as the combination of 3 things:</p>
<ol>
<li>Sequence of those 4 key-value pairs</li>
<li>Sequence of 15 hashes</li>
<li>Structural information that lets us compute the root hash out of the sequences (1) and (2)</li>
</ol>
<h2 id="generating-the-structural-information-from-the-sequence-of-keys"><a class="header" href="#generating-the-structural-information-from-the-sequence-of-keys">Generating the structural information from the sequence of keys</a></h2>
<p>In order to devise an algorithm for generating the structural information, we return to this picture
<img src="pics/prefix_groups_3.png" alt="prefix_groups_3" /></p>
<p>It can then be readily observed that the first item in any prefix group has this property that its common prefix with
the item immediately to the right (or empty string if the item is the very last) is longer than its common prefix with
the item immediately to the left (or empty string if the item is the very first). Analogously, the last item in any
prefix group has the property that its common prefix with the item immediately to the left is longer than its common
prefix with the item immediately to the right.</p>
<p>The algorithm proceeds in steps, one step for each key-value pair, in the lexicographic order of the keys. At each step,
it observes two keys (sequences of digits) - current, and succeeding. Because the algorithm emits opcodes that
manipulate the stack (technically, two stacks, but because they are always of the same lengths, we can just say &quot;stack&quot;)
, it keeps track of what is currently on the stack. Each prefix group which is currently being
&quot;assembled&quot; by the algorithm, has some number of items on the stack. This is being tracked by an item in the <code>groups</code>
slice. The index of the item in the slice is equal to the length of the prefix of the prefix group. And the <code>uint16</code>
value of the item is the bitmask, with one bit per digit (and also per item on the stack). Whenever the algorithm emits
an opcode that would push something on the stack, one of the items in the <code>groups</code> slice gains one extra bit to its
bitmask. When the algorithm emits an opcode that would pop one or more things from the stack, the corresponding item
gets removed from the <code>groups</code> slice. The slice <code>groups</code> is started off empty and it is shared between steps.
Algorithm's step can also be invoked recursively from another step, with current and preceding keys specified by the
caller.</p>
<p>A step starts with computing the prefix of the smallest prefix group that the current key belongs to. It is either the
common prefix of current key and the preceding key or the common prefix of current key and the succeeding key, whichever
is longer (if they are the same length, then they are also equal, so no ambiguity there). If the common prefix with the
succeeding key is longer, then the new prefix group is being created. If necessary, <code>groups</code> slice is expanded (by
adding 0 items) so that it has the same length as the common prefix.</p>
<p>The digit of the current key immediately following the max common prefix is called &quot;extra digit&quot;. The sequence of digits
of the current key following that extra digit is the remainder (which could be empty). The item in the <code>groups</code> slice
corresponding to the common prefix (basically <code>groups[len(common prefix)]</code>) is modified to include an extra bit
corresponding to the &quot;extra digit&quot;. If this step of the algorithm was invoked on a key-value pair (non-recursively),
then a <code>LEAF</code> (or <code>LEAFHASH</code>)
opcode is emitted, with the operand being the length of the remainder (zero if the remainder is empty). If the step of
the algorithm was invoked recursively, and the remainder is not empty, an <code>EXTENSION</code> (or <code>EXTENSIONHASH</code>) opcode is
emitted instead, with the operand being the remainder. For example, for leaf <code>12</code>, the lengths of the common prefix with
neighbours are 1 and 3. Therefore, this key will emit the opcode
<code>LEAF 4</code>, where 4 = 8 (original length) - 3 (max common prefix length) - 1 (one digit goes to the branch node for the
prefix group).</p>
<p>The following, optional, part of the step only happens if the common prefix of the current key and the preceding key is
longer or equal than the common prefix of the current key and the succeeding key, in other words, if at least one prefix
group needs to be &quot;closed&quot;. Closing a prefix group means first emitting opcode <code>BRANCH</code> or <code>BRANCHHASH</code>. The value for
the operand is taken from the item in the <code>groups</code> slice, which corresponds to the length of the prefix for this group.
Once value is taken, <code>groups</code> slice is trimmed to remove the used item. Secondly, closing a prefix groups means invoking
the step of the algorithm recursively
(unless the group that was closed was the one with the empty prefix, which encompasses all the keys). For that recursive
invocation, the prefix of the closed group is used as the current key, and the succeeding key simply passed on.
Preceding key is found as the prefix of the current key of the length equal of the highest index of non-zero item in
the <code>groups</code> (in other words, the longest prefix of a prefix group which would have something on the stack). During the
recursive invocation, the slice <code>groups</code>
is trimmed to match the length of the preceding key that was found.</p>
<p>We will walk through the steps of the algorithm for the leaf <code>30</code>, and then for the leaf <code>31</code>. For <code>30</code>, the key
is <code>33113123</code>. Its max common prefix with neighbours is <code>3311</code>. The common prefix with the preceding key is longer than
with the succeeding key, therefore the prefix group <code>3311</code> is being closed. The digit immediately following this prefix
is <code>3</code>. Since this is a non-recursive invocation, and the remainder <code>123</code> is 3 digits long, opcode <code>LEAF 3</code> is emitted.
The optional part of the step happens, and he opcode <code>BRANCH 23</code> (closing the prefix group) is emitted. Slice <code>groups</code>
contained the bit for <code>2</code> in the item <code>groups[4]</code> already, and another bit for <code>3</code> has been added, therefore we
have <code>23</code> as the operand. Slice <code>groups</code> gets trimmed to contain only 4 items. After that, the step gets invoked
recursively with current key being <code>3311</code>, and preceding key identified as <code>3</code> (there were no prefix group with
prefix <code>33</code> or <code>331</code> yet, this can be figured out by checking the <code>groups</code> slice, where the highest index with non-zero
item is 1).</p>
<p>In the recursive invocation of the step, max common prefix is <code>331</code>. The common prefix with the succeeding key is longer
than with the preceding key, therefore a new prefix group <code>331</code> is created. Slice <code>groups</code> gets extended to 4 items, and
the fourth item
(<code>group[3]</code>) gets item containing one bit for digit <code>1</code>. No more recursion.</p>
<p>For leaf <code>31</code> (key <code>33132002</code>), max common prefix is <code>331</code>. The common prefix with the preceding key is longer than with
the succeeding key, therefore the prefix group <code>331</code> is being closed. This is the group that was created during the step
for leaf <code>30</code> described above. The digit immediately following this prefix is <code>3</code>. Corresponding bit is added to the
item <code>groups[3]</code>. Since this is a non-recursive invocation, opcode <code>LEAF 4</code> is emitted (4 is the length of the
remainder <code>2002</code>). The optional part of the step happens, opcode <code>BRANCH 13</code> is emitted, and slice <code>group</code> is trimmed to
3 items to remove the item <code>groups[3]</code>. The step gets invoked recursively with current key being <code>331</code>, and preceding
key identified as <code>3</code> (there were no prefix group with prefix <code>33</code>).</p>
<p>In the recursive step, max common prefix is <code>3</code>. The common prefix with the preceding key is longer than with the
succeeding key, therefore the prefix group <code>3</code> is being closed. The digit immediately following this prefix is <code>3</code>. The
remainder <code>1</code> is non-empty, and since this is a recursive invocation, opcode
<code>EXTENSION 1</code> is emitted. The optional part of the step happens, opcode <code>BRANCH 023</code> is emitted for the prefix group <code>3</code>
being closed. Slice <code>groups</code> is trimmed to just 1 item. The step gets invoked recursively again, with current key
being <code>3</code>, and preceding key empty.</p>
<p>In the deeper recursive step, max common prefix is empty. Since the common prefix with the preceding key equals to the
common prefix with the succeeding key (they are both empty). The optional part of the step happens, opcode <code>BRANCH 0123</code>
is emitted, and <code>groups</code> is trimmed to become empty. No recursive invocation follows.</p>
<p>The step of this algorithm is implemented by the function <code>GenStructStep</code>
in <a href="../../turbo/trie/gen_struct_step.go">turbo/trie/gen_struct_step.go</a>.</p>
<h2 id="converting-sequence-of-keys-and-value-into-a-multiproof"><a class="header" href="#converting-sequence-of-keys-and-value-into-a-multiproof">Converting sequence of keys and value into a multiproof</a></h2>
<p>One of the biggest difference between Erigon and go-ethereum is in the way the Ethereum state is persisted in the
database. In go-ethereum, the model for persistence is Merkle Patricia tree. In Erigon, the model for persistence is
sequence of key-value pairs, where keys are either derived from account addresses, or from storage indices. In this
model, computing Merkle Patricia tree from part of data is a very commonly used operation. This operation is called &quot;
Resolution&quot; because it normally arises from a need to look up (resolve) some keys and corresponding values, and later
update them, thus requiring recomputation of the Merkle Patricia tree root.</p>
<p>We can use the concept of Multiproofs to define the resolution operation. If we have a set of key-value pairs, and we
need to &quot;resolve&quot; them, we effectively need to produce a multiproof for the given set of key-value pairs. To produce
such multiproof, we can use the algorithm for generating the structural information from the sequence of keys. However,
within the algorithm, choices need to be made between emitting <code>BRANCHHASH</code> and <code>BRANCH</code> opcodes (or, similarly,
between <code>LEAF</code> and <code>LEAFHASH</code>, and between <code>EXTENSION</code> and <code>EXTENSIONHASH</code>). Such choices are conceptually simple to
make - if max common prefix is also a prefix of any of the keys we are trying to resolve,
<code>BRANCH</code> should be emitted, otherwise, <code>BRANCHHASH</code> should be emitted. However, in order to make these choices
efficiently, the set of keys being resolved will be converted into a sorted list. Then, at each point when the algorithm
processes a key, it maintains references to two consecutive keys from that sorted list - one &quot;LTE&quot; (Less Than or Equal
to the currently processed key), and another &quot;GT&quot; (Greater Than the currently processed key). If max common prefix is
also prefix of either LTE or GT, then <code>BRANCH</code> opcode is emitted, otherwise, <code>BRANCHHASH</code> opcode is emitted. This is
implemented by the type <code>ResolveSet</code> in <a href="../../turbo/trie/resolve_set.go">turbo/trie/resolve_set.go</a></p>
<h2 id="extension-of-the-structure-to-support-contracts-with-contract-storage"><a class="header" href="#extension-of-the-structure-to-support-contracts-with-contract-storage">Extension of the structure to support contracts with contract storage</a></h2>
<p>When it is required to construct tries containing accounts as well as contract storage, and contract code, the set of
opcodes making up the structural information need to be extended by four more. Apart from that, a new input sequence (
tape) is added, containing the bytecodes of contracts.</p>
<ol start="8">
<li><code>CODE</code></li>
<li><code>CODEHASH</code></li>
<li><code>ACCOUNTLEAF length field-set</code></li>
<li><code>ACCOUNTLEAFHASH length field-set</code></li>
<li><code>EMPTYROOT</code></li>
</ol>
<p><code>CODE</code> opcode consumes the next item in the bytecode sequence, creates a code node and pushes it onto the node stack. It
also pushes the hash of the byte code onto the hash stack.</p>
<p><code>CODEHASH</code> opcode consumes the next hash from the hash sequence, pushes it onto the hash stack, and pushes <code>nil</code> into
the node stack.</p>
<p><code>ACCOUNTLEAF</code> opcode is similar to <code>LEAF</code>. It consumes the next item from the key tape. The rest of the semantics
depends on the value of the <code>field-set</code>. Field set can be respresented by a bitmask. In that case, bit 0 would
correspond to field 0, bit 1 (number 2) - to field 1, bit 2 (number 4) - to field 2. Currently, field 0 means account
nonce, field 1 means account balance, field 2 means contract storage, field 3 means contract code.</p>
<ul>
<li>If field 0 is present in the <code>field-set</code>, the opcode consumes one item from the nonce tape (tape 0), otherwise it
assumes default nonce (zero). This becomes the nonce of the newly created account/contract node.</li>
<li>If field 1 is present in the <code>field-set</code>, the opcode consumes one item from the balance tape (tape 1), otherwise it
assumes default balance (zero). This becomes the balance of the newly created account/contract node.</li>
<li>If field 2 is present in the <code>field-set</code>, the opcode pops a node from the node stack and a hash from the hash stack.
This node or hash (in this order of preference) becomes the storage of the newly created contract node. Storage root
can be empty (that would introduced by <code>EMPTYROOT</code> opcode).</li>
<li>If field 3 is present in the <code>field-set</code>, the opcode pops a code node from the node stack and a hash from the hash
stack. This node or hash (in the order of preference) becomes the code or code hash of the newly created contract
node.</li>
</ul>
<p>Out of all the information collected through the tapes and the stacks (as directed by the <code>field-set</code>), an account leaf
node is constructed and pushed onto the node stack. Its hash is pushed onto the hash stack. Field set is introduced to
make the specification of what is an account extensible in a backwards compatible way. If a new field is added to the
account in the future, it can be introduced without a need to re-encode the pre-existing structures.</p>
<p><code>ACCOUNTLEAFHASH</code> opcode's difference from <code>ACCOUNTLEAF</code> is that it does not push the leaf node onto the node stack,
pushing <code>nil</code> instead. The hash of would-be account leaf node is pushed onto the hash stack.</p>
<p><code>EMPTYROOT</code> is a way of placing a special value signifying an empty node onto the node stack. It also pushes the
corresponding hash onto the hash stack. This opcode is introduced because there is no way of achieving its semantics by
means of other opcodes.</p>
<h2 id="merkle-trie-root-calculation"><a class="header" href="#merkle-trie-root-calculation">Merkle trie root calculation</a></h2>
<p><strong>Theoretically:</strong> &quot;Merkle trie root calculation&quot; starts from state, build from state keys - trie, on each level of trie
calculates intermediate hash of underlying data.</p>
<p><strong>Practically:</strong> It can be implemented as &quot;Preorder trie traversal&quot; (Preorder - visit Root, visit Left, visit Right).
But, let's make couple observations to make traversal over huge state efficient.</p>
<p><strong>Observation 1:</strong> <code>CurrentStateBucket</code> already stores state keys in sorted way. Iteration over this bucket will
retrieve keys in same order as &quot;Preorder trie traversal&quot;.</p>
<p><strong>Observation 2:</strong> each Eth block - changes not big part of state - it means most of Merkle trie intermediate hashes
will not change. It means we effectively can cache them. <code>IntermediateTrieHashBucket</code> stores &quot;Intermediate hashes of all
Merkle trie levels&quot;. It also sorted and Iteration over <code>IntermediateTrieHashBucket</code> will retrieve keys in same order
as &quot;Preorder trie traversal&quot;.</p>
<p><strong>Implementation:</strong> by opening 1 Cursor on state and 1 more Cursor on intermediate hashes bucket - we will receive data
in order of &quot;Preorder trie traversal&quot;. Cursors will only do &quot;sequential reads&quot; and &quot;jumps forward&quot; - been
hardware-friendly. 1 stack keeps all accumulated hashes, when sub-trie traverse ends - all hashes pulled from stack -&gt;
hashed -&gt; new hash puts on stack - it's hash of visited sub-trie (it emulates recursive nature of &quot;Preorder trie
traversal&quot; algo).</p>
<p>Imagine that account with key 0000....00 (64 zeroes, 32 bytes of zeroes) changed. Here is an example sequence which can
be seen by running 2 Cursors:</p>
<pre><code>00   // key which came from cache, can't use it - because account with this prefix changed 
0000 // key which came from cache, can't use it - because account with this prefix changed
...
{30 zero bytes}00    // key which came from cache, can't use it - because account with this prefix changed
{30 zero bytes}0000  // Account which came from state, use it - calculate hash, jump to &quot;next sub-trie&quot;
{30 zero bytes}01    // key which came from cache, it is &quot;next sub-trie&quot;, use it, jump to &quot;next sub-trie&quot; 
{30 zero bytes}02    // key which came from cache, it is &quot;next sub-trie&quot;, use it, jump to &quot;next sub-trie&quot;
...
{30 zero bytes}ff    // key which came from cache, it is &quot;next sub-trie&quot;, use it, jump to &quot;next sub-trie&quot;
{29 zero bytes}01    // key which came from cache, it is &quot;next sub-trie&quot; (1 byte shorter key), use it, jump to &quot;next sub-trie&quot;
{29 zero bytes}02    // key which came from cache, it is &quot;next sub-trie&quot; (1 byte shorter key), use it, jump to &quot;next sub-trie&quot;
...
ff                   // key which came from cache, it is &quot;next sub-trie&quot; (1 byte shorter key), use it, jump to &quot;next sub-trie&quot;
nil                  // db returned nil - means no more keys there, done   
</code></pre>
<p>In practice Trie is not full - it means after account key <code>{30 zero bytes}0000</code> may come <code>{5 zero bytes}01</code> and amount of
iterations will not be big.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
